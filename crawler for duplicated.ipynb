{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform the court name\n",
    "def courtName(str):\n",
    "    courtName = {'南投':'NTDV', '臺中':'TCDV', '台北':'TPDV', '臺南':'TNDV', '臺東':'TTDV', '嘉義':'CYDV',\\\n",
    "                 '基隆':'KLDV', '士林':'SLDV', '宜蘭':'ILDV', '屏東':'PTDV', '彰化':'CHDV', '新北':'PCDV',\\\n",
    "                 '新竹':'SCDV', '桃園':'TYDV', '澎湖':'PHDV', '花蓮':'HLDV', '苗栗':'MLDV', '連江':'LCDV',\\\n",
    "                 '金門':'KMDV', '雲林':'ULDV', '高雄':'KSDV'}\n",
    "    return courtName[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform the jud_case to url encode\n",
    "def jud_case(str):\n",
    "    import urllib\n",
    "    jud_case = {'':str}\n",
    "    jud_case_encode = urllib.urlencode(jud_case)[1:]\n",
    "    return jud_case_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read target from list\n",
    "# data format: 9960-臺中_90_中簡_2622.txt\n",
    "def getTarget(str):\n",
    "    import codecs\n",
    "    f = codecs.open(str,'r','utf-8')\n",
    "    fcontent = f.read().encode('utf8')\n",
    "    raw = fcontent.split('\\r\\n')\n",
    "    ary = []\n",
    "    for row in raw:\n",
    "        sep = row.strip().split('-')[1].split(\".\")[0].split(\"_\")\n",
    "        # aggregate the search data to a dic\n",
    "        encoData = {'courtFullName':courtName(sep[0]), 'jud_year':sep[1], 'jud_case':jud_case(sep[2]), 'jud_no':sep[3]}\n",
    "        # this one for file saving\n",
    "        rawData = {'courtFullName':sep[0], 'jud_year':sep[1], 'jud_case':sep[2], 'jud_no':sep[3]}\n",
    "        # aggregate to ary\n",
    "        ary.append([encoData, rawData])\n",
    "    f.close()\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve the x value and return cookie\n",
    "def getCookie(court, year, case, no):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    # insert specify attributes for each case\n",
    "    url = 'http://fyjud.lawbank.com.tw/Receive2.aspx?courtFullName='+court+\\\n",
    "           '&v_court=&v_sys=&jud_year='+year+\\\n",
    "           '&jud_case='+case+\\\n",
    "           '&jud_no='+no+\\\n",
    "           '&jud_title=&jud_jmain=&keyword=&sdate=&edate=&file=&page=&id=&searchkw=&jcatagory=2'+\\\n",
    "           '&switchFrom=&issimple=-1'+\\\n",
    "           '&jminmoney=&jmaxmoney=&jminyear=&jmaxyear=&txtjudge=&txtlawyer=&lc1a=&lc1b=&lc1c='\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    # select the right part we need\n",
    "    j = soup.select('a')[0]['onclick'].split(\"'\")[1]\n",
    "    # append it after j=\n",
    "    x = 'j='+j\n",
    "    # setCookie\n",
    "    cookie = {'y':'',\\\n",
    "              'ASP.NET_SessionId':'zjafvq45bo1r5zvxjq0nyw55',\\\n",
    "              'JubFrm-pagebox':'%5EcourtFullName%3D'+court+\\\n",
    "                               '%60%5Ejud_year%3D'+year+\\\n",
    "                               '%5Ejud_case%3D'+case+\\\n",
    "                               '%5Ejud_no%3D'+no+\\\n",
    "                               '%5Ejcatagory%3D2%5Eissimple%3D-1',\\\n",
    "              '_ga':'GA1.3.473815266.1434356225',\\\n",
    "              '_gat':'1',\\\n",
    "              'x':x}\n",
    "    return cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare and retrieve the link/cookie_y of duplicate one\n",
    "def targetLinkY(ck):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    res = requests.get('http://fyjud.lawbank.com.tw/'+'listcontent5.aspx', cookies = ck)\n",
    "    # create a list for choosing the right one by comparing file size\n",
    "    compare = []\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    for each in soup.select('td[nowrap]'):\n",
    "        # append the file size to list\n",
    "        if each.text != '':\n",
    "            # change the last int 1 to 2 if your data is like '花蓮_89_訴更(一)_5.txt'\n",
    "            compare.append(int(each.text[:-2].strip().split('(')[1]))\n",
    "        # append -1 if the tag is empty\n",
    "        else:\n",
    "            compare.append(-1)\n",
    "    # find the index of the max value\n",
    "    index = compare.index(max(compare))\n",
    "    # parse the link\n",
    "    contentLink = soup.select('td[nowrap]')[index].select('a')[0]['href']\n",
    "    # parse cookie_y value\n",
    "    y = 'p='+soup.select('td[nowrap]')[index].select('a')[0]['onclick'].split(\"'\")[1]\n",
    "    return {'contentLink':contentLink, 'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeContent(li):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    cookie['y'] = linkY['y']\n",
    "    contentUrl = 'http://fyjud.lawbank.com.tw/'+linkY['contentLink']\n",
    "    res = requests.get(contentUrl, cookies = cookie)       \n",
    "    res_soup = BeautifulSoup(res.text)\n",
    "    path='%s_%s_%s_%s.txt'%(li[1]['courtFullName'], li[1]['jud_year'], li[1]['jud_case'], li[1]['jud_no'])\n",
    "    f = open(path.decode('utf-8'),'w')\n",
    "    for pre in res_soup.select('pre'):      \n",
    "        f.write(pre.text.encode('utf-8')+'\\n')\n",
    "    f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 士林 93 湖簡 387 DONE\n",
      "2 新北 93 保險 14 DONE\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "list = getTarget('missing.txt')\n",
    "i = 1\n",
    "#j = 1718\n",
    "for target in list:\n",
    "    cookie = getCookie(target[0]['courtFullName'], target[0]['jud_year'], target[0]['jud_case'], target[0]['jud_no'])\n",
    "    linkY = targetLinkY(cookie)\n",
    "    writeContent(target)\n",
    "    print i, target[1]['courtFullName'], target[1]['jud_year'], target[1]['jud_case'], target[1]['jud_no'], \"DONE\"\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "- edit LinkY to linkY <-- Done\n",
    "- def writeContent() -> def writeContent(list), also the args <-- Done\n",
    "- skip 227, 1040, 1041 <-- Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the missing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fAll = open('duplicated_list_oringinal_for_get_missing.txt', 'r')\n",
    "fRes = open('result_list.txt', 'r')\n",
    "#fMis = open('missing_list.txt', 'w')\n",
    "fAllContent = fAll.read().split('\\n')\n",
    "fResContent = fRes.read().split('\\n')\n",
    "for line in fAllContent:\n",
    "    if line not in fResContent:\n",
    "        print line\n",
    "fAll.close()\n",
    "fRes.close()\n",
    "#fMis.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "a = ['a','b','c']\n",
    "b = ['a','d']\n",
    "\n",
    "for i in a:\n",
    "    if i not in b:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ASP.NET_SessionId': 'zjafvq45bo1r5zvxjq0nyw55', 'JubFrm-pagebox': '%5EcourtFullName%3DTPDV%60%5Ejud_year%3D90%5Ejud_case%3D%E5%BA%97%E5%B0%8F%5Ejud_no%3D297%5Ejcatagory%3D2%5Eissimple%3D-1', '_ga': 'GA1.3.473815266.1434356225', 'y': '', 'x': u'j=ExKZIgGGiQD19KUxjSulmQb58Xq9tzxh/6k2CZDMXMbqn+pyISjsF42Gyv8r7WXOK2TSUk8PjqCjFgL8iLOg+iNkAojTlLxxWDw0QavV6OyoT7gSIGUwE2HJ47ggCB/3IZ/ze2onHPHbrig7DIXsGf/LKE1ffRqwJWbkFYC5v/dZGQDZG2p0ebbypK98JXfGaS1xhZcx5F3BuxM9jbPUy5VEIyeZH9KKjapjEXVcjOh3MX5ya4aG75C7j2NOFzExMEKptNhMJMau08NOiY2m8g==', '_gat': '1'}\n"
     ]
    }
   ],
   "source": [
    "cookie = getCookie('TPDV', '90', '%E5%BA%97%E5%B0%8F', '297')\n",
    "print cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contentLink': u'content3.aspx?p=NFLNW3o2iZnLciVoeEtcUHAcgcEWaOO3rtBQxD%2bfl4A%3d', 'y': u'p=wbWCgBlMA2QgJSEANuPzEsMcWQWY8JyOOlZiaeJB5cIz2GfzriHtlEpHACPm9PwA'}\n"
     ]
    }
   ],
   "source": [
    "linkY = targetLinkY(cookie)\n",
    "print linkY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天天氣真好\n",
      "今天天氣真好\n",
      "'\\xe4\\xbb\\x8a\\xe5\\xa4\\xa9\\xe5\\xa4\\xa9\\xe6\\xb0\\xa3\\xe7\\x9c\\x9f\\xe5\\xa5\\xbd'\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\IPython\\kernel\\__main__.py:12: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "encoded = '\\xe4\\xbb\\x8a\\xe5\\xa4\\xa9\\xe5\\xa4\\xa9\\xe6\\xb0\\xa3\\xe7\\x9c\\x9f\\xe5\\xa5\\xbd'\n",
    "msg = encoded.decode('utf8')\n",
    "print msg\n",
    "\n",
    "# -*- coding: utf8 -*-\n",
    "msg = u'今天天氣真好'\n",
    "encoded = msg.encode('utf8')\n",
    "print encoded\n",
    "print repr(encoded)\n",
    "\n",
    "print (msg == encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
